{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# atmacup20 1st place solution\n",
    "[1位解法](https://www.guruguru.science/competitions/27/discussions/960838f8-36ee-4002-9992-3861c37b7d62/)のシングルモデルを再現するコードを共有します。\n",
    "\n",
    "- 手元のRTX3090環境で実行時間約80min(1fold約15min)\n",
    "- CV:0.69525、Public:0.6922、Private:0.7191<br>※なぜか乱数固定ができておらず、実行のたびに若干値がブレます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48934,
     "status": "ok",
     "timestamp": 1754309500725,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "F3LieaqG4Vsh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    ModernBertForSequenceClassification,\n",
    "    PreTrainedTokenizerBase,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import polars as pl\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from box import Box\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1754309970188,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "2x42MWLv9YdP"
   },
   "outputs": [],
   "source": [
    "# yaml\n",
    "CONFIG = \"\"\"\n",
    "input_dir: ../../data/raw/input # ここは環境によって変更\n",
    "work_dir: G:/マイドライブ/competitions/atma_udemy/sample_code/1th_place_solution # ここは環境によって変更\n",
    "\n",
    "n_splits: 5\n",
    "model: sbintuitions/modernbert-ja-30m\n",
    "max_length: 1024\n",
    "optim_type: adamw_torch\n",
    "per_device_train_batch_size: 8\n",
    "gradient_accumulation_steps: 8\n",
    "per_device_eval_batch_size: 16\n",
    "eval_steps: 50\n",
    "max_steps: 1000\n",
    "max_grad_norm: 10.0\n",
    "lr: 2.0e-5\n",
    "weight_decay: 0.01\n",
    "warmup_steps: 25\n",
    "lr_scheduler_type: cosine\n",
    "\n",
    "classifier_pooling: cls\n",
    "\n",
    "seed: 42\n",
    "exp_name: atma20-bert-001\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "config = Box(yaml.safe_load(CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1754309885009,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "YznRyelpAT7z"
   },
   "outputs": [],
   "source": [
    "UDEMY_ACTIVITY_SCHEMA = {\n",
    "    \"社員番号\": pl.Utf8,\n",
    "    \"コースID\": pl.Int64,\n",
    "    \"コースタイトル\": pl.Utf8,\n",
    "    \"レクチャーもしくはクイズ\": pl.Utf8,\n",
    "    \"レクチャー/クイズID\": pl.Int64,\n",
    "    \"レクチャー/クイズの題名\": pl.Utf8,\n",
    "    \"開始日\": pl.Datetime,\n",
    "    \"終了日\": pl.Datetime,\n",
    "    \"推定完了率%\": pl.Float64,\n",
    "    \"最終結果（クイズの場合）\": pl.Float64,\n",
    "    \"マーク済み修了\": pl.Boolean,\n",
    "    \"コースカテゴリー\": pl.Utf8,\n",
    "}\n",
    "DX_SCHEMA = {\n",
    "    \"社員番号\": pl.Utf8,\n",
    "    \"研修実施日\": pl.Datetime,\n",
    "    \"研修カテゴリ\": pl.Utf8,\n",
    "    \"研修名\": pl.Utf8,\n",
    "}\n",
    "HR_SCHEMA = {\n",
    "    \"社員番号\": pl.Utf8,\n",
    "    \"カテゴリ\": pl.Utf8,\n",
    "    \"研修名\": pl.Utf8,\n",
    "    \"実施日\": pl.Utf8,\n",
    "}\n",
    "OVERTIME_WORK_BY_MONTH_SCHEMA = {\n",
    "    \"社員番号\": pl.Utf8,\n",
    "    \"date\": pl.Datetime,\n",
    "    \"hours\": pl.Float64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1754309503277,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "PcNWDr_-4MQ4"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    logits = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(logits).float().softmax(-1).numpy()[:, 1]\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "    return {\"auc\": auc}\n",
    "\n",
    "\n",
    "def make_cv(df: pl.DataFrame, n_splits: int, seed: int) -> pl.DataFrame:\n",
    "    folds = np.zeros(len(df))\n",
    "    kfold = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(\n",
    "        kfold.split(df, df.get_column(\"target\"), df.get_column(\"社員番号\"))\n",
    "    ):\n",
    "        folds[valid_index] = fold\n",
    "    return df.with_columns(pl.Series(folds, dtype=pl.Int64).alias(\"fold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロンプト作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1754309503324,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "NGY4rnip5SBB"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    udemy_activity_df: pl.DataFrame,\n",
    "    dx_df: pl.DataFrame,\n",
    "    hr_df: pl.DataFrame,\n",
    "    overtime_work_by_month_df: pl.DataFrame,\n",
    "    position_history_df: pl.DataFrame,\n",
    ") -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame, pl.DataFrame, pl.DataFrame, dict]:\n",
    "    udemy_activity_df = udemy_activity_df.with_columns(\n",
    "        (\n",
    "            pl.when(\n",
    "                (pl.col(\"終了日\") >= datetime.datetime(2022, 4, 1))\n",
    "                & (pl.col(\"終了日\") < datetime.datetime(2023, 4, 1))\n",
    "            )\n",
    "        )\n",
    "        .then(pl.lit(2022))\n",
    "        .when(\n",
    "            (pl.col(\"終了日\") >= datetime.datetime(2023, 4, 1))\n",
    "            & (pl.col(\"終了日\") < datetime.datetime(2024, 4, 1))\n",
    "        )\n",
    "        .then(pl.lit(2023))\n",
    "        .when(\n",
    "            (pl.col(\"終了日\") >= datetime.datetime(2024, 4, 1))\n",
    "            & (pl.col(\"終了日\") < datetime.datetime(2025, 4, 1))\n",
    "        )\n",
    "        .then(pl.lit(2024))\n",
    "        .when(\n",
    "            (pl.col(\"終了日\") >= datetime.datetime(2025, 4, 1))\n",
    "            & (pl.col(\"終了日\") < datetime.datetime(2026, 4, 1))\n",
    "        )\n",
    "        .then(pl.lit(2025))\n",
    "        .alias(\"year\")\n",
    "    )\n",
    "    dx_df = dx_df.with_columns(\n",
    "        (\n",
    "            pl.when(\n",
    "                (pl.col(\"研修実施日\") >= datetime.datetime(2022, 4, 1))\n",
    "                & (pl.col(\"研修実施日\") < datetime.datetime(2023, 4, 1))\n",
    "            )\n",
    "        )\n",
    "        .then(pl.lit(2022))\n",
    "        .when(\n",
    "            (pl.col(\"研修実施日\") >= datetime.datetime(2023, 4, 1))\n",
    "            & (pl.col(\"研修実施日\") < datetime.datetime(2024, 4, 1))\n",
    "        )\n",
    "        .then(pl.lit(2023))\n",
    "        .when(\n",
    "            (pl.col(\"研修実施日\") >= datetime.datetime(2024, 4, 1))\n",
    "            & (pl.col(\"研修実施日\") < datetime.datetime(2025, 4, 1))\n",
    "        )\n",
    "        .then(pl.lit(2024))\n",
    "        .alias(\"year\")\n",
    "    )\n",
    "    hr_df = (\n",
    "        hr_df.with_columns(\n",
    "            pl.col(\"実施日\")\n",
    "            .str.extract(r\"(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2})\")\n",
    "            .str.to_datetime()\n",
    "            .alias(\"date\")\n",
    "        )\n",
    "        .unique()\n",
    "        .with_columns(\n",
    "            (\n",
    "                pl.when(\n",
    "                    (pl.col(\"date\") >= datetime.datetime(2022, 4, 1))\n",
    "                    & (pl.col(\"date\") < datetime.datetime(2023, 4, 1))\n",
    "                )\n",
    "            )\n",
    "            .then(pl.lit(2022))\n",
    "            .when(\n",
    "                (pl.col(\"date\") >= datetime.datetime(2023, 4, 1))\n",
    "                & (pl.col(\"date\") < datetime.datetime(2024, 4, 1))\n",
    "            )\n",
    "            .then(pl.lit(2023))\n",
    "            .when(\n",
    "                (pl.col(\"date\") >= datetime.datetime(2024, 4, 1))\n",
    "                & (pl.col(\"date\") < datetime.datetime(2025, 4, 1))\n",
    "            )\n",
    "            .then(pl.lit(2024))\n",
    "            .when(\n",
    "                (pl.col(\"date\") >= datetime.datetime(2025, 4, 1))\n",
    "                & (pl.col(\"date\") < datetime.datetime(2026, 4, 1))\n",
    "            )\n",
    "            .then(pl.lit(2025))\n",
    "            .alias(\"year\")\n",
    "        )\n",
    "    )\n",
    "    position_history_df = position_history_df.with_columns(\n",
    "        (pl.col(\"year\") + 2000).alias(\"year\")\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        udemy_activity_df,\n",
    "        dx_df,\n",
    "        hr_df,\n",
    "        overtime_work_by_month_df,\n",
    "        position_history_df,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_data(\n",
    "    df: pl.DataFrame,\n",
    "    udemy_df: pl.DataFrame,\n",
    "    dx_df: pl.DataFrame,\n",
    "    hr_df: pl.DataFrame,\n",
    "    overtime_df: pl.DataFrame,\n",
    "    position_df: pl.DataFrame,\n",
    ") -> pl.DataFrame:\n",
    "    prompts = {}\n",
    "    employee_ids = df.get_column(\"社員番号\").unique(maintain_order=True).to_list()\n",
    "    for employee_id in tqdm(employee_ids, desc=\"Processing Prompts\"):\n",
    "        udemy_activity = udemy_df.filter(pl.col(\"社員番号\") == employee_id)\n",
    "        dx = dx_df.filter(pl.col(\"社員番号\") == employee_id)\n",
    "        hr = hr_df.filter(pl.col(\"社員番号\") == employee_id)\n",
    "        overtime = overtime_df.filter(pl.col(\"社員番号\") == employee_id)\n",
    "        position = position_df.filter(pl.col(\"社員番号\") == employee_id)\n",
    "\n",
    "        prompt = []\n",
    "        years = [2022, 2023, 2024]\n",
    "\n",
    "        for year in years:\n",
    "            prompt.append(f\"{year}年\")\n",
    "\n",
    "            # position\n",
    "            position_year = position.filter(pl.col(\"year\") == year)\n",
    "            if position_year.is_empty():\n",
    "                prompt.append(\"情報なし\")\n",
    "                prompt.append(\"\")\n",
    "                continue\n",
    "\n",
    "            assert len(position_year) == 1, \"Multiple positions found for the same year\"\n",
    "\n",
    "            prompt.append(\n",
    "                f\"{position_year.get_column('勤務区分')[0]}({position_year.get_column('役職')[0]})\"\n",
    "            )\n",
    "\n",
    "            # overtime\n",
    "            overtime_year = overtime.filter(pl.col(\"date\").dt.year() == year)\n",
    "            avg_hours = overtime_year.get_column(\"hours\").mean()\n",
    "            max_hours = overtime_year.get_column(\"hours\").max()\n",
    "            min_hours = overtime_year.get_column(\"hours\").min()\n",
    "            avg_hours_5 = round(avg_hours / 5) * 5  # Round to nearest 5\n",
    "            min_hours = round(min_hours / 5) * 5  # Round to nearest 5\n",
    "            max_hours = round(max_hours / 5) * 5  # Round to nearest 5\n",
    "            prompt.append(f\"平均残業時間: 約{avg_hours_5}時間\")\n",
    "            prompt.append(f\"最大残業時間: 約{max_hours}時間\")\n",
    "            prompt.append(f\"最小残業時間: 約{min_hours}時間\")\n",
    "\n",
    "            # dx\n",
    "            prompt.append(\"---\")\n",
    "            prompt.append(\"DX研修\")\n",
    "            dx_year = dx.filter(pl.col(\"year\") == year)\n",
    "            if not dx_year.is_empty():\n",
    "                dx_year_head = (\n",
    "                    (\n",
    "                        dx_year.group_by(\"研修カテゴリ\")\n",
    "                        .len()\n",
    "                        .sort(\"研修カテゴリ\", descending=True)[:5]\n",
    "                    )\n",
    "                    .select(\n",
    "                        (\n",
    "                            pl.col(\"研修カテゴリ\").str.replace_all(\"_\", \" \")\n",
    "                            + \": \"\n",
    "                            + pl.col(\"len\").cast(pl.Utf8)\n",
    "                            + \"回\"\n",
    "                        ).alias(\"dx_prompt\")\n",
    "                    )\n",
    "                    .to_series()\n",
    "                    .to_list()\n",
    "                )\n",
    "                prompt.extend(dx_year_head)\n",
    "\n",
    "            # hr\n",
    "            prompt.append(\"---\")\n",
    "            prompt.append(\"人事研修\")\n",
    "            hr_year = hr.filter(pl.col(\"year\") == year)\n",
    "            if not hr_year.is_empty():\n",
    "                hr_year_head = (\n",
    "                    hr_year.group_by(\"カテゴリ\")\n",
    "                    .len()\n",
    "                    .sort(\"len\", descending=True)\n",
    "                    .with_columns((pl.col(\"カテゴリ\")).alias(\"hr_prompt\"))\n",
    "                    .get_column(\"hr_prompt\")\n",
    "                    .to_list()\n",
    "                )\n",
    "                prompt.extend(hr_year_head)\n",
    "\n",
    "            # udemy_activity\n",
    "            prompt.append(\"---\")\n",
    "            prompt.append(\"動画研修\")\n",
    "            udemy_year = udemy_activity.filter(\n",
    "                pl.col(\"year\") == year,\n",
    "                pl.col(\"マーク済み修了\"),\n",
    "                pl.col(\"コースカテゴリー\").is_not_null(),\n",
    "            )\n",
    "            if not udemy_year.is_empty():\n",
    "                udemy_year_head = (\n",
    "                    (\n",
    "                        udemy_year.group_by(\"コースカテゴリー\")\n",
    "                        .len()\n",
    "                        .sort(\"コースカテゴリー\", descending=True)[:5]\n",
    "                    )\n",
    "                    .select(\n",
    "                        (\n",
    "                            pl.col(\"コースカテゴリー\")\n",
    "                            + \": \"\n",
    "                            + pl.col(\"len\").cast(pl.Utf8)\n",
    "                            + \"回\"\n",
    "                        ).alias(\"udemy_prompt\")\n",
    "                    )\n",
    "                    .to_series()\n",
    "                    .to_list()\n",
    "                )\n",
    "                prompt.extend(udemy_year_head)\n",
    "\n",
    "            prompt.append(\"\")\n",
    "\n",
    "        prompts[employee_id] = \"\\n\".join(prompt).strip()\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"社員番号\").alias(\"employee_id\"),\n",
    "        pl.col(\"category\").alias(\"category\"),\n",
    "        (pl.col(\"category\") + \"\\n\" + pl.col(\"社員番号\").replace(prompts)).alias(\"text\"),\n",
    "        pl.col(\"target\").alias(\"labels\"),\n",
    "    )\n",
    "\n",
    "    return df.select(\"employee_id\", \"category\", \"text\", \"labels\", \"fold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "DATA_DIR = Path(config.input_dir)\n",
    "WORK_DIR = Path(config.work_dir)\n",
    "shutil.rmtree(WORK_DIR, ignore_errors=True)\n",
    "WORK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "train_df = pl.read_csv(DATA_DIR / \"train.csv\")\n",
    "dx_df = pl.read_csv(DATA_DIR / \"dx.csv\", schema=DX_SCHEMA)\n",
    "hr_df = pl.read_csv(DATA_DIR / \"hr.csv\", schema=HR_SCHEMA)\n",
    "overtime_work_by_month_df = pl.read_csv(\n",
    "    DATA_DIR / \"overtime_work_by_month.csv\", schema=OVERTIME_WORK_BY_MONTH_SCHEMA\n",
    ")\n",
    "udemy_activity_df = pl.read_csv(\n",
    "    DATA_DIR / \"udemy_activity.csv\", schema=UDEMY_ACTIVITY_SCHEMA\n",
    ")\n",
    "position_history_df = pl.read_csv(DATA_DIR / \"position_history.csv\")\n",
    "\n",
    "train_df = make_cv(train_df, n_splits=config.n_splits, seed=config.seed)\n",
    "\n",
    "# preprocess data\n",
    "(udemy_activity_df, dx_df, hr_df, overtime_work_by_month_df, position_history_df) = (\n",
    "    preprocess_data(\n",
    "        udemy_activity_df, dx_df, hr_df, overtime_work_by_month_df, position_history_df\n",
    "    )\n",
    ")\n",
    "\n",
    "# プロンプト作成\n",
    "train_data = process_data(\n",
    "    train_df,\n",
    "    udemy_activity_df,\n",
    "    dx_df,\n",
    "    hr_df,\n",
    "    overtime_work_by_month_df,\n",
    "    position_history_df,\n",
    ")\n",
    "train_data.write_csv(WORK_DIR / \"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(WORK_DIR / \"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_prompt(\n",
    "    batch: dict, tokenizer: PreTrainedTokenizerBase, max_length: int\n",
    ") -> dict:\n",
    "    encoded = tokenizer(\n",
    "        batch[\"text\"], truncation=True, padding=False, max_length=max_length\n",
    "    )\n",
    "    return {**encoded, \"labels\": batch[\"labels\"], \"fold\": batch[\"fold\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ad80d0599e214b748f4128f426a08005",
      "68685f5577c642a68b5e52aaaad035c8",
      "147e4606a00641758e91a7efbd7a889d",
      "bc5ead5faf3841919e41a8492189dc90",
      "8639aff6efbb4b0cba294d270eb67723",
      "56a1c20067804b00b19a8abe950e8bea",
      "0bb436a806094e9880ff9e10ff694f91",
      "159a282d6caa4e3a867e9b3a9b6fe62e",
      "fb51f2bf43e647bdb6017fbb36ab2404",
      "e7f36a907dd2423cae4ef6e6fff81964",
      "8bd6a5a455f2423493e373161c3b9599",
      "b3e6119a805447679fd117351d0aef06",
      "43b32d9ac226479b9404bafed9206dae",
      "2d6d39b68fc8495dbdfe21f3fa925003",
      "4240215c84a44673b9f5ad1ee91d4b6e",
      "f879174ccd8444eb85892debef99be44",
      "92245916f93242ed8d6a4585e203c33c",
      "fef40cb403504c5c8069da50f376cab0",
      "69d3a91c2fd741ada29379b38c81b341",
      "2b048a10f9a74776961b78545b47e326",
      "ac92314cbf6d4419982cf191a69cbcbf",
      "d5d059751ae3403bb7cf60ee3b36618d",
      "0d8d5d591a254864b18e3d02b808e757",
      "b652124652bb48768f0812311afd104c",
      "eaf09aa7a6424b579a362e34b2d6a883",
      "af364d97f4e048edbdc677561664b31e",
      "df018c512a854c5bbb4e751f19bd4c4f",
      "43f7a26d07664bda9506bc16783356ab",
      "e0b189afa8d34c6487d97b93136d6e9f",
      "b27c7ae659d04645a6e84900f4037a7e",
      "3833ef9ab5d141d3a79b29e3d79e7711",
      "0cdd4370f1584191af58faccf09c6dd2",
      "9bd7e9c06753443aab9b3f4d0c7ead83",
      "f037e0ac5cda403bbf05c26d4cc2e662",
      "cda8e2dddfe64b98b8706b4beba2ed1b",
      "669037c9ef404255bfa02569cc751768",
      "568dcd7abe144fe3a6e040c13999cf3e",
      "3375763897314b0dacf9ef8cd4051e4f",
      "324ec3f046ed416d813af9067dc8d7a2",
      "d765faba469d4783b47e2cd50b645e59",
      "2cebb2eff7974646b30dc7f7396f8024",
      "0c9a0c43627343c78f628a175ad3882c",
      "a4a121f5542e4f76b17fd9047b01cde2",
      "bd05b5bd7cfd49569092d0f582ff4469",
      "8528b1da792a4385ad234aa1dccab4e5",
      "9616fab0cdab42c0b32f26529bd3b5c2",
      "9507f032d2ec4742a78e64ab5b7eabe2",
      "0bcd8a3f510943079b77eb837a27adf4",
      "2ca5a1c7a06548139168e505b2070f4d",
      "8fcb6795f5654d609f53d0c0773fc902",
      "41a0d27907704cb6844cb3a6c609e0e1",
      "01829b79a7d241ed8868896a03f34708",
      "1c051e3b21d3451f8df1b84ff6a22920",
      "d6770ebc85c44fdaacf20204eb408d27",
      "a1d132570781412b835d792ad15faa04",
      "4b942594322d4535be990996214f55f6",
      "75cfcaeb97344d4a8fb9e21e82d0a77b",
      "0e2c655d6cd842ef96e96f7c71f261e0",
      "a209761abc7b4b0ca79c4a35e3d93336",
      "cc818433152b4528b6311d268ad8230b",
      "a8f6be98ee9a4322968a0b11999126e1",
      "d33e4faaf12f4cb2a36c62258f38a42a",
      "3025c01b170f4f018f352c0ee5347aba",
      "e7a5404a7bd74ce2b1763cf893d5e62f",
      "a6f0f53852ee413db6af56affca6a1ee",
      "c6f3b527b6634e569079465f21f56bc8"
     ]
    },
    "executionInfo": {
     "elapsed": 48478,
     "status": "error",
     "timestamp": 1754309951179,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "jgrj5F-P8_YO",
    "outputId": "a4aafe1f-f5fa-43c6-ccdc-3ad7486d9f03"
   },
   "outputs": [],
   "source": [
    "# polars -> huggingface dataset\n",
    "train_ds = Dataset.from_polars(train_data)\n",
    "\n",
    "# encoding\n",
    "train_ds = train_ds.map(\n",
    "    lambda batch: encode_prompt(batch, tokenizer, max_length=config.max_length),\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1754309503375,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "B-wphHMF-Swg"
   },
   "outputs": [],
   "source": [
    "class ModernBertClassifier(ModernBertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        sliding_window_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        indices: Optional[torch.Tensor] = None,\n",
    "        cu_seqlens: Optional[torch.Tensor] = None,\n",
    "        max_seqlen: Optional[int] = None,\n",
    "        batch_size: Optional[int] = None,\n",
    "        seq_len: Optional[int] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs,\n",
    "    ) -> Union[tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "        self._maybe_set_compile()\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            sliding_window_mask=sliding_window_mask,\n",
    "            position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            indices=indices,\n",
    "            cu_seqlens=cu_seqlens,\n",
    "            max_seqlen=max_seqlen,\n",
    "            batch_size=batch_size,\n",
    "            seq_len=seq_len,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        last_hidden_state = outputs[0]\n",
    "\n",
    "        if self.config.classifier_pooling == \"cls\":\n",
    "            last_hidden_state = last_hidden_state[:, 0]\n",
    "        elif self.config.classifier_pooling == \"mean\":\n",
    "            last_hidden_state = (last_hidden_state * attention_mask.unsqueeze(-1)).sum(\n",
    "                dim=1\n",
    "            ) / attention_mask.sum(dim=1, keepdim=True)\n",
    "\n",
    "        pooled_output = self.head(last_hidden_state)\n",
    "        pooled_output = self.drop(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,)\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558,
     "referenced_widgets": [
      "4b2bb85cb9a1488293f8444adbfacbbc",
      "0b7f932e435742718773618a60845539",
      "9bcf7da981ca49bead117a6b8dbdfe09",
      "cd174490fd224507b508814c01134316",
      "6219b6af35a042fcb80c05a17677f433",
      "06f1b022957e4db693bfaa34ac5d2a2c",
      "a9676c6ee74c4f198e67ae6ce9869575",
      "d51b19c586994072a7ae772f210943c5",
      "55e398fbb1794da183501210a82e0697",
      "df4c0a473eb74a678e3940d680c00eb4",
      "4d4b092c6b1f42f2a618dec6415527e1",
      "299326c4deb74af194fd23e2c9f11f11",
      "f964e603b1d746978f96ed75f94b7d4a",
      "dd993e2f97614a9aa601defa5c00ef92",
      "7c5f7353523140dda5c9cfd3bb824182",
      "8b9df7a7f3ae4b1d9aa5c6a0b7651941",
      "edd12411099141ada215a77e54b3fff8",
      "dceafe1c219f40aabed79501c85b5bfa",
      "ec78bb6b6fce4d17bf56cda977668306",
      "16e932bcbe9a43f3845a3cb052042a29",
      "6cdbc856de3741d387d3e53f9512f7ee",
      "faee6587c5f34759b84aa88695aeb95c"
     ]
    },
    "executionInfo": {
     "elapsed": 282104,
     "status": "error",
     "timestamp": 1754310274608,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "LSqaV8huBhH_",
    "outputId": "82c68cc7-d1a6-4a8d-9617-541dfec3b864"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "oof_predictions = []\n",
    "for fold in range(config.n_splits):\n",
    "    print(f\"### Fold {fold + 1}/{config.n_splits} ###\")\n",
    "\n",
    "    tr_ds = train_ds.filter(lambda example: example[\"fold\"] != fold)\n",
    "    val_ds = train_ds.filter(lambda example: example[\"fold\"] == fold)\n",
    "\n",
    "    model = ModernBertClassifier.from_pretrained(\n",
    "        config.model,\n",
    "        classifier_pooling=config.classifier_pooling,\n",
    "        num_labels=2,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=WORK_DIR / f\"fold{fold + 1}\",\n",
    "        report_to=\"none\",\n",
    "        max_steps=config.max_steps,\n",
    "        per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        do_predict=True,\n",
    "        logging_strategy=\"steps\",\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        logging_steps=config.eval_steps,\n",
    "        eval_steps=config.eval_steps,\n",
    "        save_steps=config.eval_steps,\n",
    "        save_total_limit=1,\n",
    "        # load_best_model_at_end=True,\n",
    "        # metric_for_best_model=\"eval_loss\",\n",
    "        # greater_is_better=False,\n",
    "        optim=config.optim_type,\n",
    "        bf16=True,\n",
    "        learning_rate=config.lr,\n",
    "        weight_decay=config.weight_decay,\n",
    "        warmup_steps=config.warmup_steps,\n",
    "        lr_scheduler_type=config.lr_scheduler_type,\n",
    "        max_grad_norm=config.max_grad_norm,\n",
    "        seed=config.seed,\n",
    "        data_seed=config.seed,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        train_dataset=tr_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    model_path = WORK_DIR / f\"model_fold{fold + 1}\"\n",
    "    trainer.save_model(model_path)\n",
    "\n",
    "    # Remove intermediate checkpoints to save disk space\n",
    "    fold_dir = WORK_DIR / f\"fold{fold + 1}\"\n",
    "    if fold_dir.exists():\n",
    "        shutil.rmtree(fold_dir)\n",
    "\n",
    "    probs = (\n",
    "        torch.from_numpy(trainer.predict(val_ds).predictions)\n",
    "        .float()\n",
    "        .softmax(-1)\n",
    "        .numpy()[:, 1]\n",
    "    )\n",
    "    oof_df = val_ds.to_polars().with_columns(\n",
    "        pl.Series(\"prediction\", probs, dtype=pl.Float32)\n",
    "    )\n",
    "    oof_predictions.append(oof_df)\n",
    "\n",
    "    fold_score = roc_auc_score(\n",
    "        oof_df.get_column(\"labels\").to_numpy(),\n",
    "        oof_df.get_column(\"prediction\").to_numpy(),\n",
    "    )\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_score:.5f}\")\n",
    "\n",
    "oof_prediction_df = pl.concat(oof_predictions, how=\"vertical\").sort(\n",
    "    \"employee_id\", \"category\"\n",
    ")\n",
    "oof_prediction_df.select(\n",
    "    \"employee_id\", \"category\", \"fold\", \"labels\", \"prediction\"\n",
    ").write_csv(WORK_DIR / \"oof_predictions.csv\")\n",
    "valid_score = roc_auc_score(\n",
    "    oof_prediction_df.get_column(\"labels\").to_numpy(),\n",
    "    oof_prediction_df.get_column(\"prediction\").to_numpy(),\n",
    ")\n",
    "print(f\"valid_score\\t:\\t {valid_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1754309503438,
     "user": {
      "displayName": "Taichi Fujii",
      "userId": "13063050091638549131"
     },
     "user_tz": -540
    },
    "id": "nvjskkOA-Gth"
   },
   "outputs": [],
   "source": [
    "# test preprocess\n",
    "# prepare\n",
    "DATA_DIR = Path(config.input_dir)\n",
    "WORK_DIR = Path(config.work_dir)\n",
    "\n",
    "# data\n",
    "test_df = pl.read_csv(DATA_DIR / \"test.csv\").with_columns(\n",
    "    pl.lit(-1, dtype=pl.Int64).alias(\"target\"),  # dummy\n",
    "    pl.lit(-1, dtype=pl.Int64).alias(\"fold\"),  # dummy\n",
    ")\n",
    "dx_df = pl.read_csv(DATA_DIR / \"dx.csv\", schema=DX_SCHEMA)\n",
    "hr_df = pl.read_csv(DATA_DIR / \"hr.csv\", schema=HR_SCHEMA)\n",
    "overtime_work_by_month_df = pl.read_csv(\n",
    "    DATA_DIR / \"overtime_work_by_month.csv\", schema=OVERTIME_WORK_BY_MONTH_SCHEMA\n",
    ")\n",
    "udemy_activity_df = pl.read_csv(\n",
    "    DATA_DIR / \"udemy_activity.csv\", schema=UDEMY_ACTIVITY_SCHEMA\n",
    ")\n",
    "position_history_df = pl.read_csv(DATA_DIR / \"position_history.csv\")\n",
    "\n",
    "# preprocess data\n",
    "(udemy_activity_df, dx_df, hr_df, overtime_work_by_month_df, position_history_df) = (\n",
    "    preprocess_data(\n",
    "        udemy_activity_df, dx_df, hr_df, overtime_work_by_month_df, position_history_df\n",
    "    )\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(WORK_DIR / \"tokenizer\")\n",
    "\n",
    "test_data = process_data(\n",
    "    test_df,\n",
    "    udemy_activity_df,\n",
    "    dx_df,\n",
    "    hr_df,\n",
    "    overtime_work_by_month_df,\n",
    "    position_history_df,\n",
    ")\n",
    "test_data.write_csv(WORK_DIR / \"test_data.csv\")\n",
    "test_ds = Dataset.from_polars(test_data)\n",
    "test_ds = test_ds.map(\n",
    "    lambda batch: encode_prompt(batch, tokenizer, max_length=config.max_length),\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    ").remove_columns([\"fold\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_IT-nFBByrh"
   },
   "outputs": [],
   "source": [
    "# test prediction\n",
    "test_predictions = []\n",
    "for fold in range(config.n_splits):\n",
    "    print(f\"### Predicting Fold {fold + 1}/{config.n_splits} ###\")\n",
    "\n",
    "    model = ModernBertClassifier.from_pretrained(\n",
    "        WORK_DIR / f\"model_fold{fold + 1}\",\n",
    "        classifier_pooling=config.classifier_pooling,\n",
    "        num_labels=2,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    predict_args = TrainingArguments(\n",
    "        report_to=\"none\",\n",
    "        per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "        bf16=True,\n",
    "        optim=config.optim_type,\n",
    "        seed=config.seed,\n",
    "        data_seed=config.seed,\n",
    "        do_train=False,\n",
    "        do_eval=False,\n",
    "        do_predict=True,\n",
    "    )\n",
    "    predict_trainer = Trainer(\n",
    "        args=predict_args, model=model, data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    probs = (\n",
    "        torch.from_numpy(predict_trainer.predict(test_ds).predictions)\n",
    "        .float()\n",
    "        .softmax(-1)\n",
    "        .numpy()[:, 1]\n",
    "    )\n",
    "    pred_df = test_ds.to_polars().with_columns(\n",
    "        pl.lit(fold, dtype=pl.Int64).alias(\"fold\"),\n",
    "        pl.Series(\"prediction\", probs, dtype=pl.Float32),\n",
    "    )\n",
    "    test_predictions.append(pred_df)\n",
    "\n",
    "# save test predictions\n",
    "test_prediction_df = pl.concat(test_predictions, how=\"vertical\").select(\n",
    "    \"employee_id\", \"category\", \"fold\", \"prediction\"\n",
    ")\n",
    "\n",
    "submission_df = (\n",
    "    test_prediction_df.group_by(\"employee_id\", \"category\")\n",
    "    .agg(pl.col(\"prediction\").mean())\n",
    "    .select(\"employee_id\", \"category\", \"prediction\")\n",
    "    .sort(\"employee_id\", \"category\")\n",
    "    .select(pl.col(\"prediction\").alias(\"target\"))\n",
    ")\n",
    "\n",
    "test_prediction_df.write_csv(WORK_DIR / \"test_predictions.csv\")\n",
    "submission_df.write_csv(WORK_DIR / f\"{config.exp_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXmSX3pk0cEHxsEAEjLtVF",
   "gpuType": "T4",
   "mount_file_id": "1oAPz8KpVbEAbBu3XJ4qVHfR7ZUuVbZUa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "modern_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
